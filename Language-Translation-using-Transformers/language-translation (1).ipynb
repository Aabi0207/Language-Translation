{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Language Translation using Transformer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Import the Requriments","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\n\nfrom datasets import load_dataset\n\nfrom tokenizers import Tokenizer\nfrom tokenizers.models import WordPiece\nfrom tokenizers import normalizers\nfrom tokenizers.normalizers import NFD, Lowercase, StripAccents\nfrom tokenizers.pre_tokenizers import Whitespace\nfrom tokenizers.trainers import WordPieceTrainer\nfrom tokenizers import decoders\n\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import train_test_split\nimport random\nimport gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:06:27.553367Z","iopub.execute_input":"2024-12-27T03:06:27.553815Z","iopub.status.idle":"2024-12-27T03:06:33.713565Z","shell.execute_reply.started":"2024-12-27T03:06:27.553763Z","shell.execute_reply":"2024-12-27T03:06:33.712580Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Define the Configuration for the parms","metadata":{}},{"cell_type":"code","source":"n_dim = 128\nn_heads = 4\nattn_dropout = 0.1\nmlp_dropout = 0.1,\ndepth = 8\nmax_len = 128","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:06:33.715001Z","iopub.execute_input":"2024-12-27T03:06:33.715644Z","iopub.status.idle":"2024-12-27T03:06:33.720166Z","shell.execute_reply.started":"2024-12-27T03:06:33.715605Z","shell.execute_reply":"2024-12-27T03:06:33.719134Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Load the dataset","metadata":{}},{"cell_type":"code","source":"dataset1 = load_dataset('opus100', 'en-hi')\ndataset2 = load_dataset('opus100', 'en-mr')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:06:33.722241Z","iopub.execute_input":"2024-12-27T03:06:33.722542Z","iopub.status.idle":"2024-12-27T03:06:45.650633Z","shell.execute_reply.started":"2024-12-27T03:06:33.722517Z","shell.execute_reply":"2024-12-27T03:06:45.649834Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/65.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7547dfd2f4384dc88b6726e5c3322801"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/259k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"838415c7e0774d1ea294013d571cd476"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/65.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4737b55d92c24b0b98b130b30dadb0af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/247k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"244e8c0b44bf48888ecb4e1a5f72782f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"252cc848fe3b4b93adbe8e2600172205"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/534319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77b72ffa49014c0cb24c947fa75aab1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"546eec976a0847b3abb1ea52771ef0b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/128k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d2f7ba89c5b44b2b31c53b6f452003b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/1.58M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ec80e7a487f4ea4b59af90d159fcf0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/127k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddb3cd04d869412cafa1d623ee365e24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0365ab575fb4afc99524d040079acac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/27007 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d88656255704624bc358b3efdb6d9d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc5ff95644b2430191212bec51d00a7f"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"dataset1, dataset2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:06:45.652051Z","iopub.execute_input":"2024-12-27T03:06:45.652344Z","iopub.status.idle":"2024-12-27T03:06:45.658433Z","shell.execute_reply.started":"2024-12-27T03:06:45.652319Z","shell.execute_reply":"2024-12-27T03:06:45.657381Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(DatasetDict({\n     test: Dataset({\n         features: ['translation'],\n         num_rows: 2000\n     })\n     train: Dataset({\n         features: ['translation'],\n         num_rows: 534319\n     })\n     validation: Dataset({\n         features: ['translation'],\n         num_rows: 2000\n     })\n }),\n DatasetDict({\n     test: Dataset({\n         features: ['translation'],\n         num_rows: 2000\n     })\n     train: Dataset({\n         features: ['translation'],\n         num_rows: 27007\n     })\n     validation: Dataset({\n         features: ['translation'],\n         num_rows: 2000\n     })\n }))"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df1_train = pd.DataFrame(dataset1['train']['translation'], columns=['en', 'hi']).rename(columns={'en': 'lang1', 'hi': 'lang2'})\ndf1_val = pd.DataFrame(dataset1['test']['translation'], columns=['en', 'hi']).rename(columns={'en': 'lang1', 'hi': 'lang2'})\ndf1_test = pd.DataFrame(dataset1['validation']['translation'], columns=['en', 'hi']).rename(columns={'en': 'lang1', 'hi': 'lang2'})\n\ndf1_train['lang2_id'] = 'hi'\ndf1_test['lang2_id'] = 'hi'\ndf1_val['lang2_id'] = 'hi'\n\ndf2_train = pd.DataFrame(dataset2['train']['translation'], columns=['en', 'mr']).rename(columns={'en': 'lang1', 'mr': 'lang2'})\ndf2_val = pd.DataFrame(dataset2['test']['translation'], columns=['en', 'mr']).rename(columns={'en': 'lang1', 'mr': 'lang2'})\ndf2_test = pd.DataFrame(dataset2['validation']['translation'], columns=['en', 'mr']).rename(columns={'en': 'lang1', 'mr': 'lang2'})\n\ndf2_train['lang2_id'] = 'mr'\ndf2_test['lang2_id'] = 'mr'\ndf2_val['lang2_id'] = 'mr'\n\ntrain_df = pd.concat([df1_train, df2_train]).reset_index(drop=True)\ntest_df = pd.concat([df1_test, df2_test]).reset_index(drop=True)\nval_df = pd.concat([df1_val, df2_val]).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:06:45.659430Z","iopub.execute_input":"2024-12-27T03:06:45.659715Z","iopub.status.idle":"2024-12-27T03:06:50.398570Z","shell.execute_reply.started":"2024-12-27T03:06:45.659683Z","shell.execute_reply":"2024-12-27T03:06:50.397385Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:06:50.399550Z","iopub.execute_input":"2024-12-27T03:06:50.399854Z","iopub.status.idle":"2024-12-27T03:06:50.415493Z","shell.execute_reply.started":"2024-12-27T03:06:50.399827Z","shell.execute_reply":"2024-12-27T03:06:50.414487Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                  lang1  \\\n0                                  No, no, not so fast.   \n1                                              , eject!   \n2                                        I'm Dr. Messa.   \n3     So we notify the cops about big ticket sales a...   \n4     receiving what their Lord has given them, for ...   \n...                                                 ...   \n3995                     He did it not once, but twice.   \n3996                             Tom turned the tap on.   \n3997                    Are you listening to the radio?   \n3998                   Do you know what they're called?   \n3999                                               None   \n\n                                                  lang2 lang2_id  \n0                      तुम इतनी आसानी से छूट नहीं सकते.       hi  \n1                                              , बेदखल!       hi  \n2                                            Messa हूँ.       hi  \n3     तोहमबड़ीटिकटोंकीबिक्रीकेबारे मेंपुलिस सूचित......       hi  \n4     जो कुछ उनके रब ने उन्हें दिया, वे उसे ले रहे ह...       hi  \n...                                                 ...      ...  \n3995                   त्याने एकदाच नाही तर दोनदा केलं.       mr  \n3996                                टॉमने नळ चालू केला.       mr  \n3997                                  रेडियो ऐकतोयस का?       mr  \n3998             त्यांना काय म्हणतात तुला माहीत आहे का?       mr  \n3999                                          काही नाही       mr  \n\n[4000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lang1</th>\n      <th>lang2</th>\n      <th>lang2_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No, no, not so fast.</td>\n      <td>तुम इतनी आसानी से छूट नहीं सकते.</td>\n      <td>hi</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>, eject!</td>\n      <td>, बेदखल!</td>\n      <td>hi</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I'm Dr. Messa.</td>\n      <td>Messa हूँ.</td>\n      <td>hi</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>So we notify the cops about big ticket sales a...</td>\n      <td>तोहमबड़ीटिकटोंकीबिक्रीकेबारे मेंपुलिस सूचित......</td>\n      <td>hi</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>receiving what their Lord has given them, for ...</td>\n      <td>जो कुछ उनके रब ने उन्हें दिया, वे उसे ले रहे ह...</td>\n      <td>hi</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>He did it not once, but twice.</td>\n      <td>त्याने एकदाच नाही तर दोनदा केलं.</td>\n      <td>mr</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>Tom turned the tap on.</td>\n      <td>टॉमने नळ चालू केला.</td>\n      <td>mr</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>Are you listening to the radio?</td>\n      <td>रेडियो ऐकतोयस का?</td>\n      <td>mr</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>Do you know what they're called?</td>\n      <td>त्यांना काय म्हणतात तुला माहीत आहे का?</td>\n      <td>mr</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>None</td>\n      <td>काही नाही</td>\n      <td>mr</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"len(train_df), len(test_df), len(val_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:06:50.416463Z","iopub.execute_input":"2024-12-27T03:06:50.416750Z","iopub.status.idle":"2024-12-27T03:06:50.735179Z","shell.execute_reply.started":"2024-12-27T03:06:50.416724Z","shell.execute_reply":"2024-12-27T03:06:50.734150Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(561326, 4000, 4000)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"full_df = pd.concat([train_df, val_df])\nlang1, lang2 = list(full_df['lang1']), list(full_df['lang2'])\nfull = lang1+lang2\nrandom.shuffle(full)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:06:50.736264Z","iopub.execute_input":"2024-12-27T03:06:50.736646Z","iopub.status.idle":"2024-12-27T03:06:51.825223Z","shell.execute_reply.started":"2024-12-27T03:06:50.736608Z","shell.execute_reply":"2024-12-27T03:06:51.824224Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Tokenize the data","metadata":{}},{"cell_type":"markdown","source":"### Train the tokenizer","metadata":{}},{"cell_type":"code","source":"bert_tokenizer = Tokenizer(WordPiece(unk_token='<unk>'))\nbert_tokenizer.normalizer = normalizers.Sequence([Lowercase()])\nbert_tokenizer.pre_tokenizer = Whitespace()\n\ntrainer = WordPieceTrainer(special_tokens=['<unk>', '<pad>', '<s-en>', '<s-hi>', '<s-mr>', '</s>'])\n\nbert_tokenizer.train_from_iterator(full, trainer)\nbert_tokenizer.enable_padding(\n    pad_id=bert_tokenizer.token_to_id(\"<pad>\"),\n    length=max_len,\n    pad_token='<pad>'\n)\nbert_tokenizer.enable_truncation(max_len)\n\nbase = Path('translator/tokenizer')\nbase.mkdir(exist_ok=True, parents=True)\nbert_tokenizer.save(str(base/'en_hi_mr.json'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:06:51.827767Z","iopub.execute_input":"2024-12-27T03:06:51.828087Z","iopub.status.idle":"2024-12-27T03:07:06.214958Z","shell.execute_reply.started":"2024-12-27T03:06:51.828061Z","shell.execute_reply":"2024-12-27T03:07:06.213715Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Tokenize the dataset","metadata":{"execution":{"iopub.status.busy":"2024-12-26T16:12:50.215514Z","iopub.execute_input":"2024-12-26T16:12:50.215993Z","iopub.status.idle":"2024-12-26T16:12:50.223513Z","shell.execute_reply.started":"2024-12-26T16:12:50.215949Z","shell.execute_reply":"2024-12-26T16:12:50.222541Z"}}},{"cell_type":"code","source":"x = bert_tokenizer.encode(f\"<s-hi>{lang2[1234]}</s>\")\nfor a, b in zip(x.ids, x.tokens):\n    if b != \"<pad>\":\n        print(f\"{a} -> {b}\")\n\nprint(f\"\\n {bert_tokenizer.decode(x.ids)} \\n\\n\")\n\nx = bert_tokenizer.encode(f\"<s-mr>{lang2[-1234]}</s>\")\nfor a, b in zip(x.ids, x.tokens):\n    if b != \"<pad>\":\n        print(a, \"->\", b)\n\nprint(f\"\\n {bert_tokenizer.decode(x.ids)} \\n\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:07:06.216375Z","iopub.execute_input":"2024-12-27T03:07:06.216666Z","iopub.status.idle":"2024-12-27T03:07:06.233196Z","shell.execute_reply.started":"2024-12-27T03:07:06.216641Z","shell.execute_reply":"2024-12-27T03:07:06.231918Z"}},"outputs":[{"name":"stdout","text":"3 -> <s-hi>\n3747 -> खाली\n1654 -> किए\n2039 -> जाने\n762 -> के\n4852 -> दौरान\n2378 -> त्रुटि\n5 -> </s>\n\n खाली किए जाने के दौरान त्रुटि \n\n\n4 -> <s-mr>\n3647 -> ती\n14477 -> जुळ\n422 -> ##ी\n1819 -> आहे\n19 -> .\n5 -> </s>\n\n ती जुळ ##ी आहे . \n\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print('pad', \"->\" ,bert_tokenizer.token_to_id('<pad>'))\nprint('en', \"->\" ,bert_tokenizer.token_to_id('<s-en>'))\nprint('hi', \"->\" ,bert_tokenizer.token_to_id('<s-hi>'))\nprint('mr', \"->\" ,bert_tokenizer.token_to_id('<s-mr>'))\nprint('eos', \"->\" ,bert_tokenizer.token_to_id('</s>'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:07:06.234200Z","iopub.execute_input":"2024-12-27T03:07:06.234535Z","iopub.status.idle":"2024-12-27T03:07:06.258684Z","shell.execute_reply.started":"2024-12-27T03:07:06.234506Z","shell.execute_reply":"2024-12-27T03:07:06.257132Z"}},"outputs":[{"name":"stdout","text":"pad -> 1\nen -> 2\nhi -> 3\nmr -> 4\neos -> 5\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Create the data loader","metadata":{}},{"cell_type":"code","source":"class Dataset:\n    def __init__(self,df):\n        self.df = df\n    def __len__(self,):\n        return len(self.df)\n    def __getitem__(self,idx):\n        sample = self.df.iloc[idx,:]\n        en,lang2 = sample['lang1'], sample['lang2']\n        start_token = \"<s-hi>\" if sample['lang2_id']=='hi' else \"<s-mr>\"\n        en = bert_tokenizer.encode(f'<s-en>{en.strip()}</s>').ids\n        l2 = bert_tokenizer.encode(f'{start_token}{lang2.strip()}</s>').ids\n        l2_shift = l2.copy()\n        l2_shift[:-1] = l2[1:]\n        l2_shift[-1] = bert_tokenizer.token_to_id('<pad>')\n        \n        en = torch.tensor(en,dtype=torch.long)\n        l2 = torch.tensor(l2,dtype=torch.long)\n        l2_shift = torch.tensor(l2_shift,dtype=torch.long)\n        l2_shift[l2_shift==1]=-100\n        return en,l2,l2_shift","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:07:06.260106Z","iopub.execute_input":"2024-12-27T03:07:06.260524Z","iopub.status.idle":"2024-12-27T03:07:06.282761Z","shell.execute_reply.started":"2024-12-27T03:07:06.260481Z","shell.execute_reply":"2024-12-27T03:07:06.281270Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_ids = Dataset(train_df)\nval_ids = Dataset(val_df)\ntest_ids = Dataset(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:07:06.284208Z","iopub.execute_input":"2024-12-27T03:07:06.284598Z","iopub.status.idle":"2024-12-27T03:07:06.309595Z","shell.execute_reply.started":"2024-12-27T03:07:06.284562Z","shell.execute_reply":"2024-12-27T03:07:06.307974Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_ids[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:07:06.310733Z","iopub.execute_input":"2024-12-27T03:07:06.311159Z","iopub.status.idle":"2024-12-27T03:07:06.387415Z","shell.execute_reply.started":"2024-12-27T03:07:06.311122Z","shell.execute_reply":"2024-12-27T03:07:06.386226Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(tensor([    2,    38, 13883,    40,     5,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1]),\n tensor([  3, 219, 470, 885,  19,   5,   1,   1,   1,   1,   1,   1,   1,   1,\n           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n           1,   1]),\n tensor([ 219,  470,  885,   19,    5, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100]))"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## Build the model","metadata":{}},{"cell_type":"markdown","source":"### Define the RMSNorm","metadata":{}},{"cell_type":"code","source":"class RMSNorm(nn.Module):\n    def __init__(self, d, p=-1, eps=1e-8, bias=False):\n        super().__init__()\n        \n        self.d = d\n        self.p = p\n        self.eps = eps\n        self.bias = bias\n\n        self.scale = nn.Parameter(torch.ones(d))\n        self.register_parameter(\"scale\", self.scale)\n\n        if self.bias:\n            self.offset = nn.Parameter(torch.zeros(d))\n            self.register_parameter(\"offset\", self.offset)\n\n    def forward(self, x):\n        if self.p < 0. or self.p >= 1.:\n            norm_x = x.norm(2, dim=-1, keepdim=True)\n            d_x = self.d\n        else:\n            partial_size = int(self.d * self.p)\n            partial_x, _ = torch.split(x, [partial_size, self.d - partial_size], dim=-1)\n            norm_x = partial_x.norm(2, dim=-1, keepdim=True)\n            d_x = partial_size\n\n        rms_x = norm_x * d_x **(-1./2)\n        x_normed = x / (rms_x + self.eps)\n\n        if self.bias:\n            return self.scale * x_normed + self.offset\n\n        return self.scal * x_normed\n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:09:36.133595Z","iopub.execute_input":"2024-12-27T03:09:36.134387Z","iopub.status.idle":"2024-12-27T03:09:36.144289Z","shell.execute_reply.started":"2024-12-27T03:09:36.134339Z","shell.execute_reply":"2024-12-27T03:09:36.143036Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### Multihead Attention","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, dim, n_heads, dropout=0.):\n        super().__init__()  # Fixed syntax\n        self.dim = dim\n        self.n_heads = n_heads\n        assert dim % n_heads == 0, 'dim should be divisible by n_heads'\n        self.head_dim = self.dim // self.n_heads\n        \n        # Linear layers for query, key, and value transformations\n        self.q = nn.Linear(dim, dim, bias=False)\n        self.k = nn.Linear(dim, dim, bias=False)\n        self.v = nn.Linear(dim, dim, bias=False)\n\n        # Dropout for attention weights\n        self.attn_dropout = nn.Dropout(dropout)\n        # Scaling factor for dot-product attention\n        self.scale = self.head_dim ** -0.5\n        # Linear layer for output projection\n        self.out_proj = nn.Linear(dim, dim, bias=False)\n\n    def forward(self, q, k, v, mask=None):\n        B, T, C = q.shape  # [batch_size, seq_len, dim]\n\n        # Linear projections for Q, K, V\n        q = self.q(q)  # [B, T, C]\n        k = self.k(k)  # [B, T, C]\n        v = self.v(v)  # [B, T, C]\n\n        # Reshape and permute for multi-head attention\n        q = q.view(B, T, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n        k = k.view(B, T, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n        v = v.view(B, T, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n\n        # Compute scaled dot-product attention\n        wei = torch.matmul(q, k.transpose(-1, -2)) * self.scale  # [B, n_heads, T, T]\n\n        # Apply mask before softmax\n        if mask is not None:\n            mask = mask.to(dtype=wei.dtype, device=wei.device)  # Fixed variable name\n            a, b = wei.size(-2), wei.size(-1)\n            wei = wei.masked_fill(mask[:, :, :a, :b] == 0, float('-inf'))\n\n        # Apply softmax and dropout\n        wei = F.softmax(wei, dim=-1)  # [B, n_heads, T, T]\n        wei = self.attn_dropout(wei)\n\n        # Compute attention output\n        attn = torch.matmul(wei, v)  # [B, n_heads, T, head_dim]\n\n        # Rearrange dimensions and merge heads\n        attn = attn.permute(0, 2, 1, 3).contiguous().view(B, T, C)  # [B, T, C]\n\n        # Final output projection\n        out = self.out_proj(attn)  # [B, T, C]\n        return out\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### FeedForward","metadata":{}},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self, dim, dropout=0.):\n        super().__init__()\n        self.ffw = nn.Sequential(\n            nn.Linear(dim, dim*4, bias=False),\n            nn.Dropout(dropout),\n            nn.GELU(),\n            nn.Linear(dim*4, dim, bias=False)\n        )\n\n    def forward(self, x):\n        out = self.ffw(x)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T03:59:33.579950Z","iopub.execute_input":"2024-12-27T03:59:33.580337Z","iopub.status.idle":"2024-12-27T03:59:33.586238Z","shell.execute_reply.started":"2024-12-27T03:59:33.580308Z","shell.execute_reply":"2024-12-27T03:59:33.585106Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}